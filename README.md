# Czech Lip-reading model

This repository contains source code for creating a dataset and training and evaluation of models implemented for my Diploma Thesis.

The details for each procedure can be found in separate files: [dataset collection](./dataset_collection/dataset_collection.md), [data pre-processing](./preparation/my_preparation.md), [configuration files](./configs/configs.md), [train and evaluation](./train_eval.md) and [other utils](./utils.md).

If you already have data that need to be pre-processed, start with [data pre-processing](./preparation/my_preparation). 


The pre-trained English model can be obtained from [Visual Speech Recognition for Multiple Languages in the Wild](https://github.com/mpc001/Visual_Speech_Recognition_for_Multiple_Languages) and [Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels](https://github.com/mpc001/auto_avsr).